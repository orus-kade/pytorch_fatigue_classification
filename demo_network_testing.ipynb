{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "demo_network_testing.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1RoU3rA8E3tbUBKR44e3j1_2ZnQvYwK0q",
      "authorship_tag": "ABX9TyOkSs1wEXJmaTqlvHq84b17",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/orus-kade/pytorch_fatigue_classification/blob/master/demo_network_testing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rkVlv-koqwQk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import sys\n",
        "sys.path.append('/content/drive/My Drive/fatigue')\n",
        "import transforms as T\n",
        "from torchvision import transforms, models\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "\n"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AWqy0rpi34a4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# dir_path = '/content/drive/My Drive/fatigue/faces/no_dataset_faces'\n",
        "dir_path = '/content/drive/My Drive/fatigue/faces/val_data_second_minute/0_normal/08'\n",
        "target = 0\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2PO8hRQZrjmF",
        "colab_type": "text"
      },
      "source": [
        "#For CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PlTUVYuDrg5j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_model_CNN(model_name, model_path, device):\n",
        "  if model_name == 'r3d_18':\n",
        "    model = models.video.r3d_18(pretrained=False)\n",
        "  elif model_name == 'r2plus1d_18':\n",
        "    model = models.video.r2plus1d_18(pretrained=False)\n",
        "  elif model_name == 'mc3_18':\n",
        "    model = models.video.mc3_18(pretrained=False)\n",
        "  else:\n",
        "    return None  \n",
        "  model.fc = torch.nn.Linear(model.fc.in_features, 2)  \n",
        "  model = torch.load(model_path)\n",
        "  model.eval()\n",
        "  model = model.to(device)\n",
        "  return model\n",
        "\n",
        "def load_data_for_CNN_from_dir(dir_path):\n",
        "  paths = os.listdir(dir_path)\n",
        "  paths.sort()\n",
        "  my_face = paths[:15]\n",
        "  transforms1 = transforms.Compose([transforms.Resize((112,112)), transforms.ToTensor()])\n",
        "  transforms2 = transforms.Compose([                                      \n",
        "            T.ToFloatTensorInZeroOne(),\n",
        "            T.Normalize(mean = [0.43216, 0.394666, 0.37645], std = [0.22803, 0.22145, 0.216989])\n",
        "        ])\n",
        "  clip = torch.Tensor()\n",
        "  for img_file in [dir_path+os.path.sep+x for x in my_face]:\n",
        "    img = Image.open(img_file)\n",
        "    img_tensor = transforms1(img)\n",
        "    clip = torch.cat((clip, img_tensor.unsqueeze(0)), dim = 0)\n",
        "  clip = clip.permute(0,2,3,1)\n",
        "  clip = transforms2(clip)  \n",
        "  return clip\n",
        "\n",
        "def load_data_for_CNN_form_img_arr(img_arr):\n",
        "  transforms1 = transforms.Compose([transforms.Resize((112,112)), transforms.ToTensor()])\n",
        "  transforms2 = transforms.Compose([                                      \n",
        "            T.ToFloatTensorInZeroOne(),\n",
        "            T.Normalize(mean = [0.43216, 0.394666, 0.37645], std = [0.22803, 0.22145, 0.216989])\n",
        "        ])\n",
        "  clip = torch.Tensor()\n",
        "  for img in img_arr:\n",
        "    img_tensor = transforms1(img)\n",
        "    clip = torch.cat((clip, img_tensor.unsqueeze(0)), dim = 0)\n",
        "  clip = clip.permute(0,2,3,1)\n",
        "  clip = transforms2(clip)  \n",
        "  return clip\n",
        "\n",
        "def show_clip_frames_CNN(clip):\n",
        "  mean = np.array([0.43216, 0.394666, 0.37645])\n",
        "  std = np.array([0.22803, 0.22145, 0.216989])\n",
        "  fgs, axis = plt.subplots(3,5, figsize = (20,10))\n",
        "  for ax, i in zip (axis.ravel(), range(clip.shape[1])):\n",
        "    frame = clip.permute(1, 0, 2, 3)[i]\n",
        "    frame = (frame.permute(1,2,0).numpy() * std + mean) * 255\n",
        "    ax.imshow(frame)  \n",
        "\n",
        "def predict_CNN(model, clip, device):\n",
        "  with torch.set_grad_enabled(False):\n",
        "    pred = model(torch.unsqueeze(clip, dim=0).to(device))\n",
        "    pred = pred.argmax(dim=1).to('cpu').numpy()\n",
        "    return pred"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rp_1DaaYsU_r",
        "colab_type": "text"
      },
      "source": [
        "# For CNN+RNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oe0uJn1usYow",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HlfdK_BhsZ_2",
        "colab_type": "text"
      },
      "source": [
        "#Test CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L6Bthx3rscdj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "5a5ba7b0-802a-4868-e7ed-f40ecebc50ea"
      },
      "source": [
        "# %%time\n",
        "\n",
        "# ResNet(2+1)D все слои\n",
        "\n",
        "model_name = 'r2plus1d_18'\n",
        "model_path = '/content/drive/My Drive/fatigue/results/4rd mc3_18 pretrained/model_r2plus1d_18_all.pth'\n",
        "\n",
        "model = load_model_CNN(model_name, model_path, device)   \n",
        "# print(model)\n",
        "clip_data = load_data_for_CNN(dir_path)\n",
        "show_clip_frames_CNN(clip_data)\n",
        "print('Target {}'.format(target))\n",
        "pred = predict_CNN(model, clip_data, device)\n",
        "print('predict {}'.format(pred))\n"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:657: SourceChangeWarning: source code of class 'torch.nn.modules.conv.Conv3d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
            "  warnings.warn(msg, SourceChangeWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Target 0\n",
            "predict [0]\n",
            "CPU times: user 645 ms, sys: 125 ms, total: 770 ms\n",
            "Wall time: 862 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Yjl65iV_DxY",
        "colab_type": "text"
      },
      "source": [
        "## Some time tests"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uM4MHl_d5kbn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "outputId": "c8aef96b-8046-4b32-a158-bb0a270a15ef"
      },
      "source": [
        "%%time\n",
        "model_name = 'r2plus1d_18'\n",
        "model_path = '/content/drive/My Drive/fatigue/results/4rd mc3_18 pretrained/model_r2plus1d_18_all.pth'\n",
        "model = load_model_CNN(model_name, model_path, device)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 564 ms, sys: 80.6 ms, total: 644 ms\n",
            "Wall time: 727 ms\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:657: SourceChangeWarning: source code of class 'torch.nn.modules.conv.Conv3d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
            "  warnings.warn(msg, SourceChangeWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "28ccTcyk4_Hf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "5b023907-4e51-4287-d47d-072de8c95f22"
      },
      "source": [
        "%%time\n",
        "clip_data = load_data_for_CNN(dir_path)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Время :\n",
            "0.05176234245300293\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pPp0WcHC9mIb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img_arr = []\n",
        "paths = os.listdir(dir_path)\n",
        "paths.sort()\n",
        "my_face = paths[:15]\n",
        "for img_file in [dir_path+os.path.sep+x for x in my_face]:\n",
        "  img = Image.open(img_file)\n",
        "  img_arr.append(img)"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rO5XZKMX92Ya",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "7618cfd3-7cae-45d0-f337-de628ba410a1"
      },
      "source": [
        "%%time\n",
        "clip = load_data_for_CNN_form_img_arr(img_arr)"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 15.4 ms, sys: 907 µs, total: 16.3 ms\n",
            "Wall time: 17.2 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "il3lgJ7m5cAk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "1b73ee51-b9bf-4f52-b3ed-0883086de59c"
      },
      "source": [
        "%%time\n",
        "print('Target {}'.format(target))\n",
        "pred = predict_CNN(model, clip_data, device)\n",
        "print('predict {}'.format(pred))"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Target 0\n",
            "predict [0]\n",
            "Время :\n",
            "0.09074735641479492\n",
            "CPU times: user 54.7 ms, sys: 33 ms, total: 87.7 ms\n",
            "Wall time: 90.8 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n3tvBymiscrg",
        "colab_type": "text"
      },
      "source": [
        "#Test CNN+RNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xg_EIr3isgbu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}